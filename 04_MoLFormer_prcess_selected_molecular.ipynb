{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c49ad41-16ec-4286-9a8b-335e995bc963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog shape: (209540, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>phase</th>\n",
       "      <th>pert_id</th>\n",
       "      <th>pert_iname</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>time_h</th>\n",
       "      <th>dose_uM</th>\n",
       "      <th>dose_value</th>\n",
       "      <th>dose_unit_raw</th>\n",
       "      <th>smiles</th>\n",
       "      <th>smiles_canonical</th>\n",
       "      <th>inchi_key</th>\n",
       "      <th>compound_id</th>\n",
       "      <th>is_small_molecule</th>\n",
       "      <th>is_control</th>\n",
       "      <th>pert_type</th>\n",
       "      <th>col_pos</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AML001_CD34_24H:BRD-A03772856:0.37037</td>\n",
       "      <td>GSE92742</td>\n",
       "      <td>BRD-A03772856</td>\n",
       "      <td>BRD-A03772856</td>\n",
       "      <td>cd34</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.37037</td>\n",
       "      <td>0.37037</td>\n",
       "      <td>µM</td>\n",
       "      <td>COc1ccccc1C2N(C(=O)C3CCCN23)c4ccc(Cl)cc4</td>\n",
       "      <td>COc1ccccc1C1N(c2ccc(Cl)cc2)C(=O)C2CCCN21</td>\n",
       "      <td>YSPMFQJSWDVJME-UHFFFAOYSA-N</td>\n",
       "      <td>YSPMFQJSWDVJME-UHFFFAOYSA-N</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>434316</td>\n",
       "      <td>GSE92742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AML001_CD34_24H:BRD-A03772856:1.11111</td>\n",
       "      <td>GSE92742</td>\n",
       "      <td>BRD-A03772856</td>\n",
       "      <td>BRD-A03772856</td>\n",
       "      <td>cd34</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.11111</td>\n",
       "      <td>1.11111</td>\n",
       "      <td>µM</td>\n",
       "      <td>COc1ccccc1C2N(C(=O)C3CCCN23)c4ccc(Cl)cc4</td>\n",
       "      <td>COc1ccccc1C1N(c2ccc(Cl)cc2)C(=O)C2CCCN21</td>\n",
       "      <td>YSPMFQJSWDVJME-UHFFFAOYSA-N</td>\n",
       "      <td>YSPMFQJSWDVJME-UHFFFAOYSA-N</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>434315</td>\n",
       "      <td>GSE92742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AML001_CD34_24H:BRD-A03772856:10</td>\n",
       "      <td>GSE92742</td>\n",
       "      <td>BRD-A03772856</td>\n",
       "      <td>BRD-A03772856</td>\n",
       "      <td>cd34</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>µM</td>\n",
       "      <td>COc1ccccc1C2N(C(=O)C3CCCN23)c4ccc(Cl)cc4</td>\n",
       "      <td>COc1ccccc1C1N(c2ccc(Cl)cc2)C(=O)C2CCCN21</td>\n",
       "      <td>YSPMFQJSWDVJME-UHFFFAOYSA-N</td>\n",
       "      <td>YSPMFQJSWDVJME-UHFFFAOYSA-N</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>434313</td>\n",
       "      <td>GSE92742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sig_id     phase        pert_id  \\\n",
       "0  AML001_CD34_24H:BRD-A03772856:0.37037  GSE92742  BRD-A03772856   \n",
       "1  AML001_CD34_24H:BRD-A03772856:1.11111  GSE92742  BRD-A03772856   \n",
       "2       AML001_CD34_24H:BRD-A03772856:10  GSE92742  BRD-A03772856   \n",
       "\n",
       "      pert_iname cell_id  time_h   dose_uM  dose_value dose_unit_raw  \\\n",
       "0  BRD-A03772856    cd34    24.0   0.37037     0.37037            µM   \n",
       "1  BRD-A03772856    cd34    24.0   1.11111     1.11111            µM   \n",
       "2  BRD-A03772856    cd34    24.0  10.00000    10.00000            µM   \n",
       "\n",
       "                                     smiles  \\\n",
       "0  COc1ccccc1C2N(C(=O)C3CCCN23)c4ccc(Cl)cc4   \n",
       "1  COc1ccccc1C2N(C(=O)C3CCCN23)c4ccc(Cl)cc4   \n",
       "2  COc1ccccc1C2N(C(=O)C3CCCN23)c4ccc(Cl)cc4   \n",
       "\n",
       "                           smiles_canonical                    inchi_key  \\\n",
       "0  COc1ccccc1C1N(c2ccc(Cl)cc2)C(=O)C2CCCN21  YSPMFQJSWDVJME-UHFFFAOYSA-N   \n",
       "1  COc1ccccc1C1N(c2ccc(Cl)cc2)C(=O)C2CCCN21  YSPMFQJSWDVJME-UHFFFAOYSA-N   \n",
       "2  COc1ccccc1C1N(c2ccc(Cl)cc2)C(=O)C2CCCN21  YSPMFQJSWDVJME-UHFFFAOYSA-N   \n",
       "\n",
       "                   compound_id  is_small_molecule  is_control pert_type  \\\n",
       "0  YSPMFQJSWDVJME-UHFFFAOYSA-N               True       False    trt_cp   \n",
       "1  YSPMFQJSWDVJME-UHFFFAOYSA-N               True       False    trt_cp   \n",
       "2  YSPMFQJSWDVJME-UHFFFAOYSA-N               True       False    trt_cp   \n",
       "\n",
       "   col_pos   dataset  \n",
       "0   434316  GSE92742  \n",
       "1   434315  GSE92742  \n",
       "2   434313  GSE92742  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "\n",
    "BASE    = \"/ShangGaoAIProjects/Lingge/LINCS/data\"\n",
    "PROC    = f\"{BASE}/Processed_data\"\n",
    "OUT_DIR = f\"{PROC}/L1000gctx_process\"\n",
    "\n",
    "CAT_PATH = f\"{OUT_DIR}/Y_landmark_train_catalog_canonical.index.parquet\"\n",
    "CAT = pd.read_parquet(CAT_PATH)\n",
    "\n",
    "print(\"Catalog shape:\", CAT.shape)\n",
    "display(CAT.head(3))\n",
    "\n",
    "# 我们将使用这几列（如缺失就提醒你）\n",
    "need_cols = [\"sig_id\", \"smiles_canonical\", \"cell_id\", \"dose_uM\"]\n",
    "missing = [c for c in need_cols if c not in CAT.columns]\n",
    "if missing:\n",
    "    print(\"⚠️ 缺少列：\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "244adf7a-19cb-4916-9c66-0e67a210d550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique valid SMILES: 9866\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 1.29kB [00:00, 3.28MB/s]\n",
      "tokenization_molformer_fast.py: 6.50kB [00:00, 18.9MB/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/ibm-research/MoLFormer-XL-both-10pct:\n",
      "- tokenization_molformer_fast.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "vocab.json: 41.6kB [00:00, 86.9MB/s]\n",
      "tokenizer.json: 54.0kB [00:00, 105MB/s]\n",
      "special_tokens_map.json: 100%|█████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 1.05MB/s]\n",
      "config.json: 1.01kB [00:00, 3.30MB/s]\n",
      "configuration_molformer.py: 7.60kB [00:00, 23.7MB/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/ibm-research/MoLFormer-XL-both-10pct:\n",
      "- configuration_molformer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "modeling_molformer.py: 39.3kB [00:00, 92.8MB/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/ibm-research/MoLFormer-XL-both-10pct:\n",
      "- modeling_molformer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "model.safetensors: 100%|█████████████████████████████████████████████████████████████| 187M/187M [00:04<00:00, 42.6MB/s]\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix: (9866, 768) | finite ratio: 1.0 | bad batches: 0\n",
      "Saved:\n",
      "  /ShangGaoAIProjects/Lingge/LINCS/data/Processed_data/L1000gctx_process/uniq_smiles_with_emb_row.parquet\n",
      "  /ShangGaoAIProjects/Lingge/LINCS/data/Processed_data/L1000gctx_process/molformer_unique_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "# STEP 16: 从 Hugging Face 下载 MoLFormer 并对唯一 SMILES 编码（FP32，避免 NaN/Inf）\n",
    "import os, numpy as np, pandas as pd, torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# ====== 路径与输入 ======\n",
    "BASE     = \"/ShangGaoAIProjects/Lingge/LINCS/data\"\n",
    "PROC     = f\"{BASE}/Processed_data\"\n",
    "OUT_DIR  = f\"{PROC}/L1000gctx_process\"\n",
    "CAT_PATH = f\"{OUT_DIR}/Y_landmark_train_catalog_canonical.index.parquet\"\n",
    "\n",
    "# 选用的公开权重（MoLFormer）\n",
    "HF_MODEL_ID = \"ibm-research/MoLFormer-XL-both-10pct\"\n",
    "# 可选：指定 HF 本地缓存目录（避免每次重复下载）\n",
    "HF_CACHE_DIR = f\"{BASE}/Models/HF_cache\"\n",
    "os.makedirs(HF_CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# ====== 读取 catalog，提取唯一 SMILES ======\n",
    "CAT = pd.read_parquet(CAT_PATH)\n",
    "SMI_COL = \"smiles_canonical\" if \"smiles_canonical\" in CAT.columns else \"smiles\"\n",
    "assert SMI_COL in CAT.columns, f\"catalog 缺少 {SMI_COL} 列\"\n",
    "\n",
    "smiles_series = CAT[SMI_COL].astype(str)\n",
    "mask_valid = (~smiles_series.isna()) & (smiles_series.str.len() > 0) & (smiles_series != \"-666\")\n",
    "uniq_smiles = smiles_series[mask_valid].drop_duplicates().tolist()\n",
    "print(\"Unique valid SMILES:\", len(uniq_smiles))\n",
    "\n",
    "# ====== 设备与模型（下载自 HF，信任自定义代码；强制 FP32）======\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    HF_MODEL_ID,\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=HF_CACHE_DIR\n",
    ")\n",
    "model = AutoModel.from_pretrained(\n",
    "    HF_MODEL_ID,\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=HF_CACHE_DIR\n",
    ")\n",
    "\n",
    "# 某些 tokenizer 可能没有 pad_token，给个兜底\n",
    "if tokenizer.pad_token is None:\n",
    "    # 优先用 eos，其次添加一个新 pad token\n",
    "    if tokenizer.eos_token is not None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    else:\n",
    "        tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model.eval().to(device).to(torch.float32)   # 关键：FP32，避免 NaN/Inf\n",
    "torch.set_grad_enabled(False)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ====== 编码（批量；禁用 autocast；每批做有限值检查）======\n",
    "batch_size = 256  # 显存不够就降到 128/64\n",
    "embeds = []\n",
    "bad_spans = 0\n",
    "\n",
    "def forward_encode(smiles_list, dev):\n",
    "    toks = tokenizer(\n",
    "        smiles_list,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(dev)\n",
    "    out = model(**toks)  # 不用 autocast\n",
    "    if hasattr(out, \"pooler_output\") and out.pooler_output is not None:\n",
    "        emb = out.pooler_output\n",
    "    elif hasattr(out, \"last_hidden_state\"):\n",
    "        emb = out.last_hidden_state[:, 0, :]  # CLS\n",
    "    elif isinstance(out, (tuple, list)) and len(out) > 0:\n",
    "        emb = out[0][:, 0, :]\n",
    "    else:\n",
    "        raise RuntimeError(\"无法从 MoLFormer 输出结构中找到 embedding 向量。\")\n",
    "    return emb.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "for i in range(0, len(uniq_smiles), batch_size):\n",
    "    chunk = uniq_smiles[i:i+batch_size]\n",
    "    # 首选：device（GPU/CPU）FP32\n",
    "    try:\n",
    "        emb_np = forward_encode(chunk, device)\n",
    "    except Exception as e:\n",
    "        print(f\"[forward error @ {i}:{i+batch_size} on {device}] {e}\")\n",
    "        emb_np = None\n",
    "\n",
    "    # 有限值检查；如失败，回退到 CPU 再算一次\n",
    "    if emb_np is None or not np.isfinite(emb_np).all():\n",
    "        try:\n",
    "            emb_np_cpu = forward_encode(chunk, torch.device(\"cpu\"))\n",
    "            emb_np = emb_np_cpu\n",
    "        except Exception as e2:\n",
    "            print(f\"[fallback CPU error @ {i}:{i+batch_size}] {e2}\")\n",
    "            # 兜底：本批置零，后续你也可以改成跳过\n",
    "            d_tmp = emb_np.shape[1] if isinstance(emb_np, np.ndarray) and emb_np.ndim == 2 else 768\n",
    "            emb_np = np.zeros((len(chunk), d_tmp), dtype=np.float32)\n",
    "            bad_spans += 1\n",
    "\n",
    "    # 最终确保没有 NaN/Inf（若仍有，置零）\n",
    "    if not np.isfinite(emb_np).all():\n",
    "        mask_bad = ~np.isfinite(emb_np).all(axis=1)\n",
    "        if mask_bad.any():\n",
    "            emb_np[mask_bad] = 0.0\n",
    "\n",
    "    embeds.append(emb_np)\n",
    "\n",
    "emb_matrix = np.vstack(embeds).astype(np.float32)\n",
    "d_emb = emb_matrix.shape[1]\n",
    "finite_ratio = float(np.isfinite(emb_matrix).mean())\n",
    "print(\"Embedding matrix:\", emb_matrix.shape, \"| finite ratio:\", finite_ratio, \"| bad batches:\", bad_spans)\n",
    "\n",
    "# ====== 保存唯一库（SMILES→embedding 行号）======\n",
    "uniq_df = pd.DataFrame({SMI_COL: uniq_smiles})\n",
    "uniq_df[\"emb_row\"] = np.arange(len(uniq_smiles), dtype=np.int32)\n",
    "\n",
    "uniq_smiles_path = f\"{OUT_DIR}/uniq_smiles_with_emb_row.parquet\"\n",
    "np.save(f\"{OUT_DIR}/molformer_unique_embeddings.npy\", emb_matrix)\n",
    "uniq_df.to_parquet(uniq_smiles_path, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" \", uniq_smiles_path)\n",
    "print(\" \", f\"{OUT_DIR}/molformer_unique_embeddings.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6ea5aa-57e0-41b1-ba79-1e0f0cc87b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: 9866 × 768\n",
      "Rows with NaN: 0\n",
      "Rows with Inf:  0\n",
      "Zero-norm rows: 0\n",
      "Norm stats: {'mean': 16.07752227783203, 'std': 0.9821127653121948, 'min': 13.601053237915039, 'p1': 14.305994558334351, 'p5': 14.756412982940674, 'p50': 15.933931350708008, 'p95': 17.908660888671875, 'p99': 18.93819389343262, 'max': 24.17510414123535}\n",
      "Dims with ~zero std: 0 / 768\n",
      "Exact duplicate embeddings: 0\n",
      "QC summary: {'n_rows': 9866, 'n_dims': 768, 'n_nan_rows': 0, 'n_inf_rows': 0, 'n_zero_norm_rows': 0, 'n_outlier_norm_rows': 25, 'n_exact_duplicate_rows': 0, 'norm_stats': {'mean': 16.07752227783203, 'std': 0.9821127653121948, 'min': 13.601053237915039, 'p1': 14.305994558334351, 'p5': 14.756412982940674, 'p50': 15.933931350708008, 'p95': 17.908660888671875, 'p99': 18.93819389343262, 'max': 24.17510414123535}, 'iqr_bounds': {'low': 11.833098411560059, 'high': 20.168317556381226}}\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "OUT_DIR = \"/ShangGaoAIProjects/Lingge/LINCS/data/Processed_data/L1000gctx_process\"\n",
    "\n",
    "# 载入在 Step 16 保存的唯一 SMILES 与向量库\n",
    "uniq_df    = pd.read_parquet(f\"{OUT_DIR}/uniq_smiles_with_emb_row.parquet\")  # 包含列：smiles_canonical / 或 smiles、emb_row\n",
    "emb_matrix = np.load(f\"{OUT_DIR}/molformer_unique_embeddings.npy\")           # 形状 (n_unique, d)\n",
    "\n",
    "n, d = emb_matrix.shape\n",
    "print(f\"Embedding matrix shape: {n} × {d}\")\n",
    "\n",
    "# 1) 基础数值检查：NaN / Inf / 行范数\n",
    "has_nan = np.isnan(emb_matrix)\n",
    "has_inf = ~np.isfinite(emb_matrix)\n",
    "\n",
    "row_nan = has_nan.any(axis=1)\n",
    "row_inf = has_inf.any(axis=1)\n",
    "row_norm = np.linalg.norm(emb_matrix, axis=1)\n",
    "\n",
    "n_nan = int(row_nan.sum())\n",
    "n_inf = int(row_inf.sum())\n",
    "n_zero = int((row_norm < 1e-8).sum())\n",
    "\n",
    "print(f\"Rows with NaN: {n_nan}\")\n",
    "print(f\"Rows with Inf:  {n_inf}\")\n",
    "print(f\"Zero-norm rows: {n_zero}\")\n",
    "\n",
    "# 2) 范数分布摘要（看有没有特别离谱的向量）\n",
    "norm_stats = {\n",
    "    \"mean\": float(row_norm.mean()),\n",
    "    \"std\":  float(row_norm.std()),\n",
    "    \"min\":  float(row_norm.min()),\n",
    "    \"p1\":   float(np.percentile(row_norm, 1)),\n",
    "    \"p5\":   float(np.percentile(row_norm, 5)),\n",
    "    \"p50\":  float(np.percentile(row_norm, 50)),\n",
    "    \"p95\":  float(np.percentile(row_norm, 95)),\n",
    "    \"p99\":  float(np.percentile(row_norm, 99)),\n",
    "    \"max\":  float(row_norm.max()),\n",
    "}\n",
    "print(\"Norm stats:\", norm_stats)\n",
    "\n",
    "# 3) 维度层面分布（极端维度有时提示编码异常）\n",
    "dim_mean = emb_matrix.mean(axis=0)\n",
    "dim_std  = emb_matrix.std(axis=0)\n",
    "dim_std_small = int((dim_std < 1e-6).sum())  # 基本不变的维度数\n",
    "print(f\"Dims with ~zero std: {dim_std_small} / {d}\")\n",
    "\n",
    "# 4) 精确重复向量检测（逐行完全一样）\n",
    "#    用“按行唯一”方式找重复：把 float32 转成 bytes view 来做 exact match\n",
    "#    注：这是“完全一致”的严格重复，近似重复不在此列\n",
    "view = emb_matrix.view([('f', emb_matrix.dtype, d)])  # 把每行视作一个复合类型\n",
    "_, unique_idx, inverse = np.unique(view, return_index=True, return_inverse=True)\n",
    "n_unique_rows = len(unique_idx)\n",
    "n_dupe_rows = n - n_unique_rows\n",
    "print(f\"Exact duplicate embeddings: {n_dupe_rows}\")\n",
    "\n",
    "# 5) 判定异常的规则与导出\n",
    "#    - 含 NaN/Inf\n",
    "#    - 零范数\n",
    "#    - 范数离群：使用 IQR（Q1-3*IQR, Q3+3*IQR）或 > mean+6*std 作为保守阈值\n",
    "q1, q3 = np.percentile(row_norm, [25, 75])\n",
    "iqr = q3 - q1\n",
    "low_thr = q1 - 3 * iqr\n",
    "high_thr = q3 + 3 * iqr\n",
    "six_sigma = (row_norm > norm_stats[\"mean\"] + 6*norm_stats[\"std\"]) | (row_norm < max(1e-12, norm_stats[\"mean\"] - 6*norm_stats[\"std\"]))\n",
    "\n",
    "is_outlier_norm = (row_norm < low_thr) | (row_norm > high_thr) | six_sigma\n",
    "\n",
    "# 整理 DataFrame\n",
    "smiles_col = \"smiles_canonical\" if \"smiles_canonical\" in uniq_df.columns else \"smiles\"\n",
    "qc_df = pd.DataFrame({\n",
    "    \"emb_row\": uniq_df[\"emb_row\"].to_numpy(),\n",
    "    smiles_col: uniq_df[smiles_col].astype(str).to_numpy(),\n",
    "    \"has_nan\": row_nan,\n",
    "    \"has_inf\": row_inf,\n",
    "    \"norm\": row_norm,\n",
    "    \"outlier_norm\": is_outlier_norm,\n",
    "})\n",
    "\n",
    "# 标记精确重复（除第一条之外的重复行）\n",
    "# inverse 给出每行对应的“唯一代表”的编号；相同编号表示重复\n",
    "# 统计每个代表的出现次数，>1 的都属于重复簇\n",
    "rep_counts = np.bincount(inverse)\n",
    "is_dupe = rep_counts[inverse] > 1\n",
    "qc_df[\"exact_duplicate_vec\"] = is_dupe\n",
    "\n",
    "# 汇总异常数量\n",
    "summary = {\n",
    "    \"n_rows\": n,\n",
    "    \"n_dims\": d,\n",
    "    \"n_nan_rows\": int(qc_df[\"has_nan\"].sum()),\n",
    "    \"n_inf_rows\": int(qc_df[\"has_inf\"].sum()),\n",
    "    \"n_zero_norm_rows\": int((qc_df[\"norm\"] < 1e-8).sum()),\n",
    "    \"n_outlier_norm_rows\": int(qc_df[\"outlier_norm\"].sum()),\n",
    "    \"n_exact_duplicate_rows\": int(qc_df[\"exact_duplicate_vec\"].sum()),\n",
    "    \"norm_stats\": norm_stats,\n",
    "    \"iqr_bounds\": {\"low\": float(low_thr), \"high\": float(high_thr)},\n",
    "}\n",
    "\n",
    "print(\"QC summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf1c69bb-05ee-4a54-90da-3ef48f5296ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209540, 768)\n",
      "Saved RAW mol embeddings: /ShangGaoAIProjects/Lingge/LINCS/data/Processed_data/L1000gctx_process/X_mol_molformer_768d.npy\n",
      "(209540, 768)\n",
      "Saved L2-normalized mol embeddings: /ShangGaoAIProjects/Lingge/LINCS/data/Processed_data/L1000gctx_process/X_mol_molformer_768d_l2.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, os\n",
    "\n",
    "OUT_DIR  = \"/ShangGaoAIProjects/Lingge/LINCS/data/Processed_data/L1000gctx_process\"\n",
    "CAT_PATH = f\"{OUT_DIR}/Y_landmark_train_catalog_canonical.index.parquet\"\n",
    "\n",
    "CAT = pd.read_parquet(CAT_PATH)\n",
    "SMI_COL = \"smiles_canonical\" if \"smiles_canonical\" in CAT.columns else \"smiles\"\n",
    "\n",
    "uniq_df    = pd.read_parquet(f\"{OUT_DIR}/uniq_smiles_with_emb_row.parquet\")  # SMI_COL, emb_row\n",
    "emb_matrix = np.load(f\"{OUT_DIR}/molformer_unique_embeddings.npy\")           # (n_unique, 768)\n",
    "d_emb = emb_matrix.shape[1]\n",
    "\n",
    "# 构建映射：SMILES → 行号\n",
    "smiles_to_row = dict(zip(uniq_df[SMI_COL].tolist(), uniq_df[\"emb_row\"].tolist()))\n",
    "emb_row_idx = CAT[SMI_COL].astype(str).map(smiles_to_row)\n",
    "\n",
    "# 理论上不应有缺失；若有，给个显式报错以免静默错配\n",
    "if emb_row_idx.isna().any():\n",
    "    miss_n = int(emb_row_idx.isna().sum())\n",
    "    print(\"⚠️ 有未命中的 SMILES 行数：\", miss_n)\n",
    "    print(CAT.loc[emb_row_idx.isna(), [SMI_COL]].head())\n",
    "    raise ValueError(\"存在 SMILES 未命中唯一库，请先排查。\")\n",
    "\n",
    "emb_row_idx = emb_row_idx.to_numpy(dtype=np.int64)\n",
    "\n",
    "# 写 raw 版本\n",
    "N = len(CAT)\n",
    "X_raw_path = f\"{OUT_DIR}/X_mol_molformer_{d_emb}d.npy\"\n",
    "X_raw = np.memmap(X_raw_path, mode=\"w+\", dtype=\"float32\", shape=(N, d_emb))\n",
    "print(X_raw.shape)\n",
    "\n",
    "stride = 50000\n",
    "for i in range(0, N, stride):\n",
    "    sl = slice(i, min(i+stride, N))\n",
    "    rows = emb_row_idx[sl]\n",
    "    X_raw[sl, :] = emb_matrix[rows, :]\n",
    "\n",
    "del X_raw  # 关闭写句柄\n",
    "print(\"Saved RAW mol embeddings:\", X_raw_path)\n",
    "\n",
    "# 同步写 L2-normalized 版本（逐行）\n",
    "X_l2_path = f\"{OUT_DIR}/X_mol_molformer_{d_emb}d_l2.npy\"\n",
    "X_l2 = np.memmap(X_l2_path, mode=\"w+\", dtype=\"float32\", shape=(N, d_emb))\n",
    "print(X_l2.shape)\n",
    "\n",
    "# 为节省内存，分块做 L2\n",
    "def _l2norm(a, axis=1, eps=1e-8):\n",
    "    n = np.linalg.norm(a, axis=axis, keepdims=True)\n",
    "    n[n < eps] = 1.0\n",
    "    return a / n\n",
    "\n",
    "emb_mem = np.memmap(X_raw_path, mode=\"r\", dtype=\"float32\", shape=(N, d_emb))\n",
    "for i in range(0, N, stride):\n",
    "    sl = slice(i, min(i+stride, N))\n",
    "    X_l2[sl, :] = _l2norm(emb_mem[sl, :])\n",
    "\n",
    "del X_l2, emb_mem\n",
    "print(\"Saved L2-normalized mol embeddings:\", X_l2_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ce093-e5a1-468e-b6c5-b01074fa9ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diffusion)",
   "language": "python",
   "name": "diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
